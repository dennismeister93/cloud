{
  "data": [
    {
      "id": "kilo/auto",
      "name": "Kilo: Auto",
      "created": 0,
      "description": "Automatically routes your request to the best model for the task.",
      "architecture": {
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other"
      },
      "top_provider": {
        "is_moderated": false,
        "context_length": 200000,
        "max_completion_tokens": 64000
      },
      "pricing": {
        "prompt": "0.0000010",
        "completion": "0.0000010",
        "request": "0",
        "image": "0",
        "web_search": "0",
        "internal_reasoning": "0"
      },
      "context_length": 200000,
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "tools",
        "reasoning",
        "include_reasoning"
      ],
      "preferredIndex": -1
    },
    {
      "id": "minimax/minimax-m2.1:free",
      "canonical_slug": "minimax/minimax-m2.1:free",
      "hugging_face_id": "",
      "name": "MiniMax: MiniMax M2.1 (free)",
      "created": 1756238927,
      "description": "MiniMax-M2.1 is a lightweight, state-of-the-art large language model optimized for coding, agentic workflows, and modern application development. With only 10 billion activated parameters, it delivers a major jump in real-world capability while maintaining exceptional latency, scalability, and cost efficiency.\n\nCompared to its predecessor, M2.1 delivers cleaner, more concise outputs and faster perceived response times. It shows leading multilingual coding performance across major systems and application languages, achieving 49.4% on Multi-SWE-Bench and 72.5% on SWE-Bench Multilingual, and serves as a versatile agent “brain” for IDEs, coding tools, and general-purpose assistance.",
      "context_length": 204800,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000000",
        "completion": "0.0000000",
        "request": "0",
        "image": "0",
        "web_search": "0",
        "internal_reasoning": "0"
      },
      "top_provider": {
        "context_length": 204800,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "per_request_limits": null,
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "tools",
        "reasoning",
        "include_reasoning"
      ],
      "default_parameters": {},
      "preferredIndex": 1,
      "settings": {
        "included_tools": [
          "search_and_replace"
        ],
        "excluded_tools": [
          "apply_diff",
          "edit_file"
        ]
      }
    },
    {
      "id": "z-ai/glm-4.7:free",
      "canonical_slug": "z-ai/glm-4.7:free",
      "hugging_face_id": "",
      "name": "Z.AI: GLM 4.7 (free)",
      "created": 1756238927,
      "description": "GLM-4.7 is Z.AI's latest flagship model, featuring upgrades in two key areas: enhanced programming capabilities and more stable multi-step reasoning/execution. It demonstrates significant improvements in executing complex agent tasks while delivering more natural conversational experiences and superior front-end aesthetics.",
      "context_length": 202752,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000000",
        "completion": "0.0000000",
        "request": "0",
        "image": "0",
        "web_search": "0",
        "internal_reasoning": "0"
      },
      "top_provider": {
        "context_length": 202752,
        "max_completion_tokens": 65535,
        "is_moderated": false
      },
      "per_request_limits": null,
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "tools",
        "reasoning",
        "include_reasoning"
      ],
      "default_parameters": {},
      "preferredIndex": 2,
      "versioned_settings": {
        "4.146.0": {
          "included_tools": [
            "write_file",
            "edit_file"
          ],
          "excluded_tools": [
            "apply_diff"
          ]
        }
      }
    },
    {
      "id": "giga-potato",
      "canonical_slug": "giga-potato",
      "hugging_face_id": "",
      "name": "Giga Potato (free)",
      "created": 1756238927,
      "description": "Giga Potato is a stealth model deeply optimized for agentic programming, with visual understanding capability. It is provided free of charge in Kilo Code for a limited time.\n**Note:** Prompts and completions are logged and may be used to improve the model.",
      "context_length": 256000,
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000000",
        "completion": "0.0000000",
        "request": "0",
        "image": "0",
        "web_search": "0",
        "internal_reasoning": "0",
        "input_cache_read": "0.00000000"
      },
      "top_provider": {
        "context_length": 256000,
        "max_completion_tokens": 32000,
        "is_moderated": false
      },
      "per_request_limits": null,
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "tools",
        "reasoning",
        "include_reasoning"
      ],
      "default_parameters": {},
      "preferredIndex": 4,
      "versioned_settings": {
        "4.146.0": {
          "included_tools": [
            "write_file",
            "edit_file"
          ],
          "excluded_tools": [
            "apply_diff"
          ]
        }
      }
    },
    {
      "id": "arcee-ai/trinity-large-preview:free",
      "canonical_slug": "arcee-ai/trinity-large-preview:free",
      "hugging_face_id": "",
      "name": "Arcee AI: Trinity Large Preview (free)",
      "created": 1756238927,
      "description": "Trinity Large Preview is a state-of-the-art large language model from Arcee AI, optimized for coding and general-purpose assistance.",
      "context_length": 128000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000000",
        "completion": "0.0000000",
        "request": "0",
        "image": "0",
        "web_search": "0",
        "internal_reasoning": "0"
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": false
      },
      "per_request_limits": null,
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "tools"
      ],
      "default_parameters": {},
      "preferredIndex": 5
    },
    {
      "id": "anthropic/claude-sonnet-4",
      "name": "Claude Sonnet 4",
      "created": 1714000000,
      "description": "Claude Sonnet 4",
      "architecture": {
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "claude"
      },
      "top_provider": {
        "is_moderated": true
      },
      "pricing": {
        "prompt": "0.000003",
        "completion": "0.000015",
        "image": "0",
        "request": "0",
        "input_cache_read": "0",
        "input_cache_write": "0",
        "web_search": "0",
        "internal_reasoning": "0"
      },
      "context_length": 200000
    },
    {
      "id": "anthropic/claude-3.7-sonnet",
      "name": "Claude 3.7 Sonnet",
      "created": 1714000000,
      "description": "Claude 3.7 Sonnet model",
      "architecture": {
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "claude"
      },
      "top_provider": {
        "is_moderated": true
      },
      "pricing": {
        "prompt": "0.000003",
        "completion": "0.000015",
        "image": "0",
        "request": "0",
        "input_cache_read": "0",
        "input_cache_write": "0",
        "web_search": "0",
        "internal_reasoning": "0"
      },
      "context_length": 200000
    },
    {
      "id": "google/gemini-2.5-pro",
      "name": "Gemini 2.5 Pro",
      "created": 1713000000,
      "description": "Gemini 2.5 Pro model",
      "architecture": {
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "gemini"
      },
      "top_provider": {
        "is_moderated": true
      },
      "pricing": {
        "prompt": "0.00000125",
        "completion": "0.00001",
        "image": "0",
        "request": "0",
        "input_cache_read": "0",
        "input_cache_write": "0",
        "web_search": "0",
        "internal_reasoning": "0"
      },
      "context_length": 1000000,
      "versioned_settings": {
        "4.146.0": {
          "included_tools": [
            "write_file",
            "edit_file"
          ],
          "excluded_tools": [
            "apply_diff"
          ]
        }
      }
    },
    {
      "id": "openai/gpt-4.1",
      "name": "GPT-4.1",
      "created": 1712000000,
      "description": "GPT-4.1 model",
      "architecture": {
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "openai"
      },
      "top_provider": {
        "is_moderated": true
      },
      "pricing": {
        "prompt": "0.000002",
        "completion": "0.000008",
        "image": "0",
        "request": "0",
        "input_cache_read": "0",
        "input_cache_write": "0",
        "web_search": "0",
        "internal_reasoning": "0"
      },
      "context_length": 128000,
      "settings": {
        "included_tools": [
          "apply_patch"
        ],
        "excluded_tools": [
          "apply_diff",
          "delete_file",
          "edit_file",
          "write_to_file"
        ]
      }
    },
    {
      "id": "some-other-model",
      "name": "Other Model",
      "created": 1711000000,
      "description": "Some other model",
      "architecture": {
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "other"
      },
      "top_provider": {
        "is_moderated": true
      },
      "pricing": {
        "prompt": "0.000001",
        "completion": "0.000005",
        "image": "0",
        "request": "0",
        "input_cache_read": "0",
        "input_cache_write": "0",
        "web_search": "0",
        "internal_reasoning": "0"
      },
      "context_length": 32000
    },
    {
      "id": "qwen/qwen3-coder",
      "name": "Qwen3 Coder",
      "created": 1715000000,
      "description": "Qwen3 Coder model",
      "architecture": {
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "qwen"
      },
      "top_provider": {
        "is_moderated": true
      },
      "pricing": {
        "prompt": "0.000001",
        "completion": "0.000003",
        "image": "0",
        "request": "0",
        "input_cache_read": "0",
        "input_cache_write": "0",
        "web_search": "0",
        "internal_reasoning": "0"
      },
      "context_length": 32000
    },
    {
      "id": "corethink:free",
      "canonical_slug": "corethink:free",
      "hugging_face_id": "",
      "name": "CoreThink (free)",
      "created": 1756238927,
      "description": "CoreThink - AI that reasons through problems instead of guessing. Available free of charge in Kilo for a limited time.",
      "context_length": 78000,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000000",
        "completion": "0.0000000",
        "request": "0",
        "image": "0",
        "web_search": "0",
        "internal_reasoning": "0"
      },
      "top_provider": {
        "context_length": 78000,
        "max_completion_tokens": 8192,
        "is_moderated": false
      },
      "per_request_limits": null,
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "tools"
      ],
      "default_parameters": {}
    },
    {
      "id": "minimax/minimax-m2.1:slackbot",
      "canonical_slug": "minimax/minimax-m2.1:slackbot",
      "hugging_face_id": "",
      "name": "MiniMax: MiniMax M2.1 (Free for Kilo for Slack)",
      "created": 1756238927,
      "description": "Free version of MiniMax M2.1 for use in Kilo for Slack only",
      "context_length": 204800,
      "architecture": {
        "modality": "text->text",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instruct_type": null
      },
      "pricing": {
        "prompt": "0.0000000",
        "completion": "0.0000000",
        "request": "0",
        "image": "0",
        "web_search": "0",
        "internal_reasoning": "0"
      },
      "top_provider": {
        "context_length": 204800,
        "max_completion_tokens": 131072,
        "is_moderated": false
      },
      "per_request_limits": null,
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "tools",
        "reasoning",
        "include_reasoning"
      ],
      "default_parameters": {},
      "settings": {
        "included_tools": [
          "search_and_replace"
        ],
        "excluded_tools": [
          "apply_diff",
          "edit_file"
        ]
      }
    }
  ]
}